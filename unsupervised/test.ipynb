{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "1ee38ef4a5a9feb55287fd749643f13d043cb0a7addaab2a9c224cbe137c0062"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "import pandas as pd\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only run this code blocks if you need to preprocess. Will make the CSV\n",
    "#Will take a long time to run\n",
    "df1 = pd.read_csv('datasets/articles1.csv', index_col=0)\n",
    "df2 = pd.read_csv('datasets/articles2.csv', index_col=0)\n",
    "df3 = pd.read_csv('datasets/articles3.csv', index_col=0)\n",
    "\n",
    "def remove_nouns(texts):\n",
    "    output = []\n",
    "    for doc in nlp.pipe(texts):\n",
    "        noun_text = \" \".join(token.lemma_ for token in doc if token.pos_ == 'NOUN')\n",
    "        output.append(noun_text)\n",
    "    return output\n",
    "\n",
    "total_df = pd.concat([df1, df2, df3])\n",
    "total_df = total_df[total_df['content'].notna()]\n",
    "total_df['content'] = remove_nouns(total_df['content'])\n",
    "total_df.to_csv(\"removed_nouns_all_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only run this block if you have the processed csv:\n",
    "total_df = pd.read_csv('removed_nouns_all_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "NMF(n_components=10, random_state=1)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "#train the classifer\n",
    "n_topics = 10\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "vec = TfidfVectorizer(max_features=5000, stop_words=\"english\", max_df=0.95, min_df=2)\n",
    "features = vec.fit_transform(total_df.content)\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "cls = NMF(n_components=n_topics, random_state=1)\n",
    "cls.fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 attack country government force war group official leader city missile security refugee administration policy people \n1 police officer shooting gun man attack video suspect car city death incident victim authority crime \n2 percent company market share price stock rate investor year business bank growth sale deal economy \n3 people film life time thing year story way family movie book world friend day child \n4 voter campaign candidate party election poll vote state nominee race delegate percent primary debate nomination \n5 email investigation campaign intelligence information official president report election administration news committee statement document press \n6 health law state court insurance care tax plan people case government coverage judge order legislation \n7 game team season player coach league year fan football ball time sport playoff point quarterback \n8 student school college campus teacher university education child parent kid class program district family community \n9 woman man abortion sex girl gender right assault child rape husband mother victim harassment comment \n"
     ]
    }
   ],
   "source": [
    "#Print top 15 words for each category\n",
    "feature_names = vec.get_feature_names()\n",
    "n_top_words = 15\n",
    "for i, topic_vec in enumerate(cls.components_):\n",
    "    print(i, end=' ')\n",
    "    for fid in topic_vec.argsort()[-1:-n_top_words-1:-1]:\n",
    "        print(feature_names[fid], end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_article(row):\n",
    "    return cls.transform(vec.transform([row])).argsort(axis=1)[:,-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classify/label our documents\n",
    "total_df['label'] = total_df['content'].apply(label_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the labeled data\n",
    "total_df.to_csv(\"labeled_articles.csv\")"
   ]
  }
 ]
}